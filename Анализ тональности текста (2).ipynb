{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788cb1e-9d51-4313-b9f8-43ded7a23cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b0ac22-f485-4a3b-af5c-280465a85e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b0049a-1cc7-4f01-8ea5-fc5f5623ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"archive (1).zip\"  # или полный путь (/content/archive.zip в Colab)\n",
    "extract_dir = \"extracted_folder3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbb451ff-6266-4e0a-93cd-16d47b9abd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архив распакован!\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print(\"Архив распакован!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d70f20a-c4c5-410f-84d4-fdc9dd0fdf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda 2\\lib\\site-packages (3.9.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in d:\\anaconda 2\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda 2\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda 2\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda 2\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in d:\\anaconda 2\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd9c04a-7dac-4579-bb83-77b583614457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in d:\\anaconda 2\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in d:\\anaconda 2\\lib\\site-packages (from scikeras) (3.9.2)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in d:\\anaconda 2\\lib\\site-packages (from scikeras) (1.5.1)\n",
      "Requirement already satisfied: absl-py in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.2.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.9)\n",
      "Requirement already satisfied: h5py in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.5.1)\n",
      "Requirement already satisfied: packaging in d:\\anaconda 2\\lib\\site-packages (from keras>=3.2.0->scikeras) (24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda 2\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda 2\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda 2\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\anaconda 2\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda 2\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda 2\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda 2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95fae1b4-1190-4e9a-a7e4-eb00d2055fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in d:\\anaconda 2\\lib\\site-packages (3.9.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: absl-py in d:\\anaconda 2\\lib\\site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda 2\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in d:\\anaconda 2\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\anaconda 2\\lib\\site-packages (from keras) (0.0.9)\n",
      "Requirement already satisfied: h5py in d:\\anaconda 2\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in d:\\anaconda 2\\lib\\site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in d:\\anaconda 2\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in d:\\anaconda 2\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\anaconda 2\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda 2\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda 2\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda 2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d96efbe-4b5b-42c7-b7ad-b449f56d6ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\anaconda 2\\lib\\site-packages (2.19.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in d:\\anaconda 2\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda 2\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in d:\\anaconda 2\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\anaconda 2\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in d:\\anaconda 2\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda 2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda 2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda 2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda 2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda 2\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda 2\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda 2\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda 2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda 2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda 2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda 2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a9304-4b8a-42b2-a05a-48ac910178e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9d37355-5fbc-4fb4-bc76-56d3f994f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding, LSTM, Dense,Dropout\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization, GRU, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52374b0a-ad62-4940-bf33-5a0b4fff99c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536809f3-1f39-4d4f-aa84-95d46075b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('extracted_folder3/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea5d9dff-c3da-4717-9ad8-bf7dec81769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[0:35000]# возьмем 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1d6047-ed10-4c12-9414-2542ad668e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Предобработка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "325f1a50-cbd9-4d50-a448-9ef390d8b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove1(text):\n",
    "  p=re.compile(\"<.*?>\")\n",
    "  return p.sub(r\"\",text)\n",
    "data['review']=data['review'].apply(remove1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7fb596c-3999-4d42-a708-72a719c86303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "  translator=str.maketrans(\"\",\"\",string.punctuation)\n",
    "  return text.translate(translator)\n",
    "data[\"review\"]=data[\"review\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd16b57-8a39-4901-8a65-7146e3bf7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_text(text):\n",
    "  return \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
    "data[\"review\"]=data[\"review\"].apply(remove_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e1e48b4-a44c-4817-be3f-57ddc01e2b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d230d13-3ce8-41a9-bcea-de31f406a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24e81c96-133d-42a8-95d6-b58981e4d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['review']\n",
    "labels =data[\"sentiment\"]\n",
    "\n",
    "lb = LabelEncoder()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "# Токенизация текста\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "x_seq = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "\n",
    "max_length = max(len(seq) for seq in x_seq)\n",
    "x_pad = pad_sequences(x_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd3b7a2f-432e-4cd7-bc0d-9e64f35873fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделение на траин, тест,вал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fdedd31-59ba-4f9e-8adb-b05de155903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_pad, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ba0ba26-0d75-4f84-b2c6-28e7697593b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c258b22-9d59-4d79-aaae-b072b950a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test_cat, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073c305-2c3a-48e5-9110-c06208faac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание модели и ее обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f2e33-1fca-46cc-a2a1-643edab04b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "161ae525-3d0e-47ae-a387-16825048b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda 2\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16282s\u001b[0m 85s/step - accuracy: 0.5135 - loss: 0.8231 - val_accuracy: 0.5005 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 2/3\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16245s\u001b[0m 85s/step - accuracy: 0.5759 - loss: 0.6647 - val_accuracy: 0.8354 - val_loss: 0.3903 - learning_rate: 0.0010\n",
      "Epoch 3/3\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16818s\u001b[0m 88s/step - accuracy: 0.8854 - loss: 0.3019 - val_accuracy: 0.8810 - val_loss: 0.2880 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, LayerNormalization\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 96\n",
    "max_length = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.39))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True, recurrent_dropout=0.3, dropout=0.37)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.55))\n",
    "\n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Dropout(0.55))\n",
    "\n",
    "model.add(Dense(64, activation='swish'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))\n",
    "\n",
    "# Оптимизатор\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=2),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=3,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c9d53-5163-400e-9a50-f0aa18a85fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранение модели(Случайно нажал на код после удаления сре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9db9f4-503d-47ec-82e0-b834598a70b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТестовая потеря: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Тестовая точность: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Сохранение модели\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Тестовая потеря: {test_loss}, Тестовая точность: {test_accuracy}\")\n",
    "\n",
    "# Сохранение модели\n",
    "model.save('my_model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f152365-faf9-42c5-ba2d-ddb01412b22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 443ms/step - accuracy: 0.8941 - loss: 0.2754\n",
      "Тестовая потеря: 0.2632194757461548, Тестовая точность: 0.8973180055618286\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model = keras.models.load_model('my_model4.h5')\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Тестовая потеря: {test_loss}, Тестовая точность: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cb03e-931f-4ad4-b083-725bc471b197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
